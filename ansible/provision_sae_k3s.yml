---
- name: Provision VMs on Proxmox and build runtime inventory
  hosts: localhost
  gather_facts: false
  vars_prompt:
    - name: proxmox_api_user
      prompt: "Proxmox API user (ex: root@pam)"
      private: false
    - name: proxmox_api_token_id
      prompt: "Proxmox token id (ex: ansible)"
      private: false
    - name: proxmox_api_token_secret
      prompt: "Proxmox token secret"
      private: true
    - name: template_vmid
      prompt: "Proxmox template VMID (recommended, leave empty to use name)"
      private: false
      default: ""
    - name: template_name
      prompt: "Proxmox template name (used if VMID is empty)"
      private: false
      default: ""
  vars:
    proxmox_api_host: "10.129.4.40"
    proxmox_api_port: "8006"
    proxmox_node: "pve"
    vm_gateway: "10.129.15.254"
    vm_netmask_cidr: "20"
    force_recreate_vms: false
    vm_disk_target_size: "20G"
    vm_ssh_user: "debian"
    vm_passwords:
      master: "master123"
      worker1: "worker123"
      worker2: "worker223"

    k3s_cluster_vms:
      - { name: "VM-Master", vmid: 301, ip: "10.129.5.203", cores: 2, memory: 4096 }
      - { name: "worker1", vmid: 302, ip: "10.129.5.204", cores: 2, memory: 3072 }
      - { name: "worker2", vmid: 303, ip: "10.129.5.205", cores: 2, memory: 3072 }

  pre_tasks:
    - name: Validate Proxmox API credentials are set
      ansible.builtin.assert:
        that:
          - proxmox_api_user | length > 0
          - proxmox_api_token_id | length > 0
          - proxmox_api_token_secret | length > 0
        fail_msg: "Set PROXMOX_API_USER, PROXMOX_API_TOKEN_ID and PROXMOX_API_TOKEN_SECRET before running this playbook."

    - name: Validate Proxmox credential format
      ansible.builtin.assert:
        that:
          - proxmox_api_user is match('^[^\s]+@[^\s]+$')
          - proxmox_api_token_id is match('^[A-Za-z0-9._-]+$')
          - proxmox_api_token_secret is not search('\s')
        fail_msg: "Invalid Proxmox credential format. Expected user like root@pam and token_id like ansible (no spaces, no URL)."

    - name: Validate template selector inputs
      ansible.builtin.assert:
        that:
          - (template_name | length > 0) or (template_vmid | length > 0)
        fail_msg: "Set PROXMOX_TEMPLATE_NAME or PROXMOX_TEMPLATE_VMID before running the playbook."

    - name: Verify Proxmox API token authentication
      ansible.builtin.uri:
        url: "https://{{ proxmox_api_host }}:{{ proxmox_api_port }}/api2/json/version"
        method: GET
        validate_certs: false
        headers:
          Authorization: "PVEAPIToken={{ proxmox_api_user }}!{{ proxmox_api_token_id }}={{ proxmox_api_token_secret }}"
        status_code: 200
        return_content: true
      register: proxmox_auth_check
      no_log: true

    - name: Confirm Proxmox auth precheck succeeded
      ansible.builtin.debug:
        msg: "Proxmox authentication precheck succeeded for {{ proxmox_api_user }}!{{ proxmox_api_token_id }}"

    - name: Fetch Proxmox VM resources
      ansible.builtin.uri:
        url: "https://{{ proxmox_api_host }}:{{ proxmox_api_port }}/api2/json/cluster/resources?type=vm"
        method: GET
        validate_certs: false
        headers:
          Authorization: "PVEAPIToken={{ proxmox_api_user }}!{{ proxmox_api_token_id }}={{ proxmox_api_token_secret }}"
        status_code: 200
        return_content: true
      register: proxmox_vm_resources
      no_log: true

    - name: Build template candidate lists
      ansible.builtin.set_fact:
        proxmox_template_names: "{{ proxmox_vm_resources.json.data | selectattr('template', 'defined') | selectattr('template', 'equalto', 1) | map(attribute='name') | list }}"
        proxmox_template_vmids: "{{ proxmox_vm_resources.json.data | selectattr('template', 'defined') | selectattr('template', 'equalto', 1) | map(attribute='vmid') | map('string') | list }}"
        proxmox_template_map: "{{ dict((proxmox_vm_resources.json.data | selectattr('template', 'defined') | selectattr('template', 'equalto', 1) | map(attribute='vmid') | map('string') | list) | zip(proxmox_vm_resources.json.data | selectattr('template', 'defined') | selectattr('template', 'equalto', 1) | map(attribute='name') | list)) }}"

    - name: Validate template exists in Proxmox
      ansible.builtin.assert:
        that:
          - (template_vmid | length == 0) or (template_vmid in proxmox_template_vmids)
          - (template_name | length == 0) or (template_name in proxmox_template_names)
        fail_msg: "Template not found. Available template names={{ proxmox_template_names }} vmids={{ proxmox_template_vmids }}"

    - name: Select clone source name
      ansible.builtin.set_fact:
        clone_source: "{{ proxmox_template_map[template_vmid] if (template_vmid | length > 0) else template_name }}"

    - name: Resolve selected template VMID
      ansible.builtin.set_fact:
        selected_template_vmid: "{{ template_vmid if (template_vmid | length > 0) else (proxmox_vm_resources.json.data | selectattr('name','equalto',template_name) | map(attribute='vmid') | map('string') | first) }}"

    - name: Read selected template config
      ansible.builtin.uri:
        url: "https://{{ proxmox_api_host }}:{{ proxmox_api_port }}/api2/json/nodes/{{ proxmox_node }}/qemu/{{ selected_template_vmid }}/config"
        method: GET
        validate_certs: false
        headers:
          Authorization: "PVEAPIToken={{ proxmox_api_user }}!{{ proxmox_api_token_id }}={{ proxmox_api_token_secret }}"
        status_code: 200
      register: selected_template_config
      no_log: true

    - name: Resolve available template system disk key
      ansible.builtin.set_fact:
        template_system_disk_key: >-
          {% if selected_template_config.json.data.scsi0 is defined %}scsi0
          {% elif selected_template_config.json.data.ide0 is defined %}ide0
          {% elif selected_template_config.json.data.virtio0 is defined %}virtio0
          {% elif selected_template_config.json.data.sata0 is defined %}sata0
          {% else %}none{% endif %}

    - name: Repair template bootdisk setting when inconsistent
      ansible.builtin.uri:
        url: "https://{{ proxmox_api_host }}:{{ proxmox_api_port }}/api2/json/nodes/{{ proxmox_node }}/qemu/{{ selected_template_vmid }}/config"
        method: PUT
        validate_certs: false
        headers:
          Authorization: "PVEAPIToken={{ proxmox_api_user }}!{{ proxmox_api_token_id }}={{ proxmox_api_token_secret }}"
        body_format: form-urlencoded
        body:
          bootdisk: "{{ template_system_disk_key }}"
          boot: "c"
        status_code: 200
      register: template_bootdisk_repair
      when:
        - template_system_disk_key != 'none'
        - selected_template_config.json.data.bootdisk is not defined or selected_template_config.json.data[selected_template_config.json.data.bootdisk] is not defined
      no_log: true
      failed_when: false

    - name: Validate selected template has an attached system disk
      ansible.builtin.assert:
        that:
          - template_system_disk_key != 'none'
        fail_msg: "Selected template is invalid (no system disk attached). Fix template {{ clone_source }} (VMID {{ selected_template_vmid }}) before running automation."

  tasks:
    - name: Remove stale SSH host keys for VM IPs
      ansible.builtin.command: "ssh-keygen -R {{ item.ip }}"
      loop: "{{ k3s_cluster_vms }}"
      loop_control:
        label: "{{ item.name }}"
      delegate_to: localhost
      become: false
      changed_when: false
      failed_when: false

    - name: Recreate VMs from clean state when requested
      community.proxmox.proxmox_kvm:
        api_host: "{{ proxmox_api_host }}"
        api_user: "{{ proxmox_api_user }}"
        api_token_id: "{{ proxmox_api_token_id }}"
        api_token_secret: "{{ proxmox_api_token_secret }}"
        validate_certs: false
        node: "{{ proxmox_node }}"
        vmid: "{{ item.vmid }}"
        state: absent
      loop: "{{ k3s_cluster_vms }}"
      loop_control:
        label: "{{ item.name }}"
      when: force_recreate_vms | bool
      failed_when: false

    - name: Read local public SSH key
      ansible.builtin.shell: |
        if [ -f "$HOME/.ssh/id_ed25519.pub" ]; then
          cat "$HOME/.ssh/id_ed25519.pub"
        elif [ -f "$HOME/.ssh/id_rsa.pub" ]; then
          cat "$HOME/.ssh/id_rsa.pub"
        else
          exit 1
        fi
      register: local_ssh_public_key
      changed_when: false
      failed_when: local_ssh_public_key.stdout | trim == ""

    - name: Detect local private SSH key path
      ansible.builtin.shell: |
        if [ -f "$HOME/.ssh/id_ed25519" ]; then
          echo "$HOME/.ssh/id_ed25519"
        elif [ -f "$HOME/.ssh/id_rsa" ]; then
          echo "$HOME/.ssh/id_rsa"
        else
          exit 1
        fi
      register: local_ssh_private_key_path
      changed_when: false
      failed_when: local_ssh_private_key_path.stdout | trim == ""

    - name: Clone VMs from template
      community.proxmox.proxmox_kvm:
        api_host: "{{ proxmox_api_host }}"
        api_user: "{{ proxmox_api_user }}"
        api_token_id: "{{ proxmox_api_token_id }}"
        api_token_secret: "{{ proxmox_api_token_secret }}"
        validate_certs: false
        node: "{{ proxmox_node }}"
        clone: "{{ clone_source }}"
        newid: "{{ item.vmid }}"
        name: "{{ item.name }}"
        cores: "{{ item.cores }}"
        memory: "{{ item.memory }}"
        full: true
        timeout: 300
        state: present
      loop: "{{ k3s_cluster_vms }}"
      loop_control:
        label: "{{ item.name }}"

    - name: Configure cloud-init and static IP
      community.proxmox.proxmox_kvm:
        api_host: "{{ proxmox_api_host }}"
        api_user: "{{ proxmox_api_user }}"
        api_token_id: "{{ proxmox_api_token_id }}"
        api_token_secret: "{{ proxmox_api_token_secret }}"
        validate_certs: false
        node: "{{ proxmox_node }}"
        vmid: "{{ item.vmid }}"
        ciuser: "{{ vm_ssh_user }}"
        cipassword: "{{ vm_passwords[item.name] }}"
        citype: nocloud
        sshkeys: "{{ local_ssh_public_key.stdout }}"
        ipconfig:
          ipconfig0: "ip={{ item.ip }}/{{ vm_netmask_cidr }},gw={{ vm_gateway }}"
        onboot: true
        agent: true
        template: false
        update: true
        state: present
      loop: "{{ k3s_cluster_vms }}"
      loop_control:
        label: "{{ item.name }}"
      no_log: true

    - name: Resize VM disk on scsi0
      community.proxmox.proxmox_disk:
        api_host: "{{ proxmox_api_host }}"
        api_user: "{{ proxmox_api_user }}"
        api_token_id: "{{ proxmox_api_token_id }}"
        api_token_secret: "{{ proxmox_api_token_secret }}"
        validate_certs: false
        vmid: "{{ item.vmid }}"
        disk: scsi0
        state: resized
        size: "{{ vm_disk_target_size }}"
      loop: "{{ k3s_cluster_vms }}"
      loop_control:
        label: "{{ item.name }}"
      register: disk_resize_scsi
      failed_when: false

    - name: Resize VM disk on virtio0 fallback
      community.proxmox.proxmox_disk:
        api_host: "{{ proxmox_api_host }}"
        api_user: "{{ proxmox_api_user }}"
        api_token_id: "{{ proxmox_api_token_id }}"
        api_token_secret: "{{ proxmox_api_token_secret }}"
        validate_certs: false
        vmid: "{{ item.vmid }}"
        disk: virtio0
        state: resized
        size: "{{ vm_disk_target_size }}"
      loop: "{{ k3s_cluster_vms }}"
      loop_control:
        label: "{{ item.name }}"
        index_var: vm_idx
      when: disk_resize_scsi is defined and (disk_resize_scsi.results[vm_idx].failed | default(false))
      failed_when: false

    - name: Start VMs
      community.proxmox.proxmox_kvm:
        api_host: "{{ proxmox_api_host }}"
        api_user: "{{ proxmox_api_user }}"
        api_token_id: "{{ proxmox_api_token_id }}"
        api_token_secret: "{{ proxmox_api_token_secret }}"
        validate_certs: false
        node: "{{ proxmox_node }}"
        vmid: "{{ item.vmid }}"
        state: started
        timeout: 300
      loop: "{{ k3s_cluster_vms }}"
      loop_control:
        label: "{{ item.name }}"

    - name: Register provisioned hosts in runtime inventory
      ansible.builtin.add_host:
        name: "{{ item.name }}"
        groups: "provisioned_nodes,{{ 'k3s_master' if item.name == 'master' else 'k3s_workers' }}"
        ansible_host: "{{ item.ip }}"
        ansible_user: "{{ vm_ssh_user }}"
        ansible_ssh_private_key_file: "{{ local_ssh_private_key_path.stdout | trim }}"
        ansible_ssh_common_args: "-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"
        ansible_python_interpreter: "/usr/bin/python3"
      loop: "{{ k3s_cluster_vms }}"
      loop_control:
        label: "{{ item.name }}"
      no_log: true

- name: Prepare OS and container registry on all K3s nodes
  hosts: provisioned_nodes
  gather_facts: false
  become: true
  vars:
    registry_host: "10.129.4.175:5050"
  tasks:
    - name: Wait until SSH TCP port is open on new VMs
      ansible.builtin.wait_for:
        host: "{{ ansible_host }}"
        port: 22
        delay: 2
        timeout: 600
      delegate_to: localhost
      become: false
      changed_when: false

    - name: Wait until remote commands execute via SSH
      ansible.builtin.raw: echo ready
      register: ssh_ready_raw
      retries: 30
      delay: 5
      until: ssh_ready_raw.rc == 0
      changed_when: false

    - name: Wait for cloud-init to complete
      ansible.builtin.raw: cloud-init status --wait || true
      changed_when: false
      failed_when: false

    - name: Install base packages
      ansible.builtin.raw: |
        export DEBIAN_FRONTEND=noninteractive
        apt-get update
        apt-get install -y curl ca-certificates python3
      changed_when: false

    - name: Disable swap permanently
      ansible.builtin.raw: |
        swapoff -a || true
        sed -ri '/\sswap\s/s/^#?/#/' /etc/fstab
      changed_when: false

    - name: Load required kernel modules
      ansible.builtin.raw: |
        modprobe overlay || true
        modprobe br_netfilter || true
      changed_when: false

    - name: Configure Kubernetes sysctl settings
      ansible.builtin.copy:
        dest: /etc/sysctl.d/99-kubernetes-cri.conf
        mode: "0644"
        content: |
          net.bridge.bridge-nf-call-iptables = 1
          net.ipv4.ip_forward = 1
          net.bridge.bridge-nf-call-ip6tables = 1

    - name: Apply sysctl settings
      ansible.builtin.command: sysctl --system
      changed_when: false

    - name: Ensure K3s config directory exists
      ansible.builtin.file:
        path: /etc/rancher/k3s
        state: directory
        mode: "0755"

    - name: Configure insecure HTTP registry for K3s runtime
      ansible.builtin.copy:
        dest: /etc/rancher/k3s/registries.yaml
        mode: "0644"
        content: |
          mirrors:
            "{{ registry_host }}":
              endpoint:
                - "http://{{ registry_host }}"

- name: Install K3s server on master
  hosts: k3s_master
  gather_facts: false
  become: true
  tasks:
    - name: Install K3s server
      ansible.builtin.shell: |
        curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="server --write-kubeconfig-mode 644 --node-ip {{ ansible_host }}" sh -
      args:
        creates: /etc/rancher/k3s/k3s.yaml

    - name: Restart K3s server to reload registries config
      ansible.builtin.service:
        name: k3s
        state: restarted

    - name: Wait for K3s API readyz
      ansible.builtin.command: k3s kubectl get --raw=/readyz
      register: master_ready
      retries: 30
      delay: 5
      until: master_ready.rc == 0
      changed_when: false

    - name: Read K3s node token
      ansible.builtin.command: cat /var/lib/rancher/k3s/server/node-token
      register: k3s_node_token_cmd
      changed_when: false

- name: Install K3s agents on workers
  hosts: k3s_workers
  gather_facts: false
  become: true
  vars:
    k3s_master_host: "{{ hostvars[groups['k3s_master'][0]].ansible_host }}"
    k3s_node_token: "{{ hostvars[groups['k3s_master'][0]].k3s_node_token_cmd.stdout | trim }}"
  tasks:
    - name: Install K3s agent
      ansible.builtin.shell: |
        curl -sfL https://get.k3s.io | K3S_URL="https://{{ k3s_master_host }}:6443" K3S_TOKEN="{{ k3s_node_token }}" INSTALL_K3S_EXEC="agent --node-ip {{ ansible_host }}" sh -
      args:
        creates: /etc/systemd/system/k3s-agent.service

    - name: Restart K3s agent to reload registries config
      ansible.builtin.service:
        name: k3s-agent
        state: restarted

- name: Deploy SAE app and monitoring stack
  hosts: k3s_master
  gather_facts: false
  become: true
  vars_prompt:
    - name: registry_username
      prompt: "GitLab registry username"
      private: false
      default: ""
    - name: registry_password
      prompt: "GitLab registry password/token"
      private: true
      default: ""
  vars:
    registry_host: "10.129.5.159:5050"
    app_namespace: "sae-production"
    repo_src_path: "{{ playbook_dir }}/.."
    repo_dst_path: "/opt/sae-dev6.01"
  tasks:
    - name: Wait for all nodes to be Ready
      ansible.builtin.command: k3s kubectl get nodes --no-headers
      register: nodes_status
      retries: 30
      delay: 5
      until: nodes_status.stdout is search(" Ready ")
      changed_when: false

    - name: Copy repository to master node
      ansible.builtin.copy:
        src: "{{ repo_src_path }}/"
        dest: "{{ repo_dst_path }}/"
        mode: preserve

    - name: Apply namespace manifest
      ansible.builtin.command: k3s kubectl apply -f {{ repo_dst_path }}/kubernetes/namespace.yaml
      changed_when: false

    - name: Create or update registry pull secret when credentials are provided
      ansible.builtin.shell: |
        k3s kubectl create secret docker-registry gitlab-registry-secret \
          --docker-server={{ registry_host }} \
          --docker-username={{ registry_username }} \
          --docker-password={{ registry_password }} \
          -n {{ app_namespace }} \
          --dry-run=client -o yaml | k3s kubectl apply -f -
      changed_when: false
      no_log: true
      when:
        - registry_username | length > 0
        - registry_password | length > 0

    - name: Ensure registry pull secret exists when credentials were not provided
      ansible.builtin.command: k3s kubectl get secret gitlab-registry-secret -n {{ app_namespace }}
      changed_when: false
      when:
        - registry_username | length == 0 or registry_password | length == 0

    - name: Apply SAE app manifests
      ansible.builtin.command: k3s kubectl apply -f {{ repo_dst_path }}/kubernetes/{{ item }}
      loop:
        - deployment.yaml
        - service.yaml
      changed_when: false

    - name: Apply monitoring manifests
      ansible.builtin.command: k3s kubectl apply -f {{ repo_dst_path }}/kubernetes/{{ item }}
      loop:
        - prometheus-config.yaml
        - prometheus.yaml
        - grafana.yaml
      changed_when: false

    - name: Restart deployments to load latest config and images
      ansible.builtin.shell: |
        k3s kubectl rollout restart deployment/sae-app -n sae-production
        k3s kubectl rollout restart deployment/prometheus -n default
        k3s kubectl rollout restart deployment/grafana -n default
      changed_when: false

    - name: Wait for SAE app rollout
      ansible.builtin.command: k3s kubectl rollout status deployment/sae-app -n sae-production --timeout=300s
      changed_when: false

    - name: Wait for Prometheus rollout
      ansible.builtin.command: k3s kubectl rollout status deployment/prometheus -n default --timeout=300s
      changed_when: false

    - name: Wait for Grafana rollout
      ansible.builtin.command: k3s kubectl rollout status deployment/grafana -n default --timeout=300s
      changed_when: false

    - name: Wait for Tornado NodePort availability
      ansible.builtin.wait_for:
        host: "{{ ansible_host }}"
        port: 30080
        delay: 2
        timeout: 180
      delegate_to: localhost
      become: false

    - name: Seed initial Tornado data when address book is empty
      ansible.builtin.shell: |
        BASE="http://{{ ansible_host }}:30080"
        CURRENT=$(curl -fsS "$BASE/addresses")
        if [ "$CURRENT" = "{}" ]; then
          curl -fsS -X POST "$BASE/addresses" \
            -H "Content-Type: application/json" \
            -d '{"full_name":"Seed User","addresses":[{"kind":"home","street_name":"Main Street","pincode":"75001","country":"France"}],"phone_numbers":[{"kind":"home","country_code":33,"local_number":123456789}],"emails":[{"kind":"home","email":"seed.user@example.com"}]}' >/dev/null
        fi
      args:
        executable: /bin/bash
      changed_when: false
      delegate_to: localhost
      become: false

    - name: Verify Tornado endpoint returns non-empty data
      ansible.builtin.shell: |
        curl -fsS "http://{{ ansible_host }}:30080/addresses" | python3 -c 'import json,sys; data=json.load(sys.stdin); assert isinstance(data,dict) and len(data)>0, "address book is empty"'
      changed_when: false
      delegate_to: localhost
      become: false

    - name: Verify Prometheus NodePort availability
      ansible.builtin.wait_for:
        host: "{{ ansible_host }}"
        port: 30090
        delay: 2
        timeout: 180
      delegate_to: localhost
      become: false

    - name: Verify Prometheus scrapes sae-app successfully
      ansible.builtin.shell: |
        curl -fsS "http://{{ ansible_host }}:30090/api/v1/query?query=up%7Bjob%3D%22sae-app%22%7D" | python3 -c 'import json,sys; payload=json.load(sys.stdin); results=payload["data"]["result"]; assert len(results)>=1, "no sae-app targets"; assert any(float(r["value"][1])>=1.0 for r in results), "sae-app targets are not UP"'
      changed_when: false
      delegate_to: localhost
      become: false

    - name: Wait for Grafana NodePort availability
      ansible.builtin.wait_for:
        host: "{{ ansible_host }}"
        port: 30030
        delay: 2
        timeout: 180
      delegate_to: localhost
      become: false

    - name: Create base Grafana dashboard JSON
      ansible.builtin.copy:
        dest: /tmp/sae-base-dashboard.json
        mode: "0644"
        content: |
          {
            "dashboard": {
              "id": null,
              "uid": "sae-base",
              "title": "SAE Base Monitoring",
              "tags": ["sae", "k3s"],
              "timezone": "browser",
              "schemaVersion": 39,
              "version": 1,
              "refresh": "5s",
              "time": {"from": "now-15m", "to": "now"},
              "panels": [
                {
                  "id": 1,
                  "type": "timeseries",
                  "title": "Pods UP (sae-app)",
                  "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0},
                  "targets": [{"refId": "A", "expr": "up{job=\"sae-app\"}", "legendFormat": "{{instance}}"}]
                },
                {
                  "id": 2,
                  "type": "timeseries",
                  "title": "HTTP Requests/sec",
                  "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8},
                  "targets": [{"refId": "A", "expr": "sum by (method, endpoint, status) (rate(addrservice_http_requests_total[1m]))", "legendFormat": "{{method}} {{endpoint}} {{status}}"}]
                },
                {
                  "id": 3,
                  "type": "timeseries",
                  "title": "P95 Request Duration",
                  "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16},
                  "targets": [{"refId": "A", "expr": "histogram_quantile(0.95, sum by (le, endpoint) (rate(addrservice_http_request_duration_seconds_bucket[5m])))", "legendFormat": "{{endpoint}}"}]
                }
              ]
            },
            "folderId": 0,
            "overwrite": true
          }

    - name: Import base Grafana dashboard
      ansible.builtin.shell: |
        curl -fsS -u admin:admin \
          -H "Content-Type: application/json" \
          -X POST "http://{{ ansible_host }}:30030/api/dashboards/db" \
          -d @/tmp/sae-base-dashboard.json >/tmp/grafana_import.out
      args:
        executable: /bin/bash
      changed_when: false

    - name: Verify dashboard exists in Grafana
      ansible.builtin.shell: |
        curl -fsS -u admin:admin "http://{{ ansible_host }}:30030/api/search?query=SAE%20Base%20Monitoring" | python3 -c 'import json,sys; data=json.load(sys.stdin); assert any(d.get("title")=="SAE Base Monitoring" for d in data), "dashboard not found"'
      changed_when: false
      delegate_to: localhost
      become: false

    - name: Show deployment summary
      ansible.builtin.shell: |
        echo "=== Nodes ==="
        k3s kubectl get nodes -o wide
        echo "=== sae-app Pods ==="
        k3s kubectl get pods -n sae-production -o wide
        echo "=== Prometheus/Grafana Pods ==="
        k3s kubectl get pods -n default -l app in \(prometheus,grafana\) -o wide
        echo "=== Services ==="
        k3s kubectl get svc -A
        echo "=== Access URLs ==="
        echo "Tornado: http://{{ ansible_host }}:30080/addresses"
        echo "Prometheus: http://{{ ansible_host }}:30090"
        echo "Grafana: http://{{ ansible_host }}:30030 (admin/admin)"
        echo "=== VM credentials ==="
        echo "master -> user: {{ vm_ssh_user }} / password: {{ vm_passwords['master'] }}"
        echo "worker1 -> user: {{ vm_ssh_user }} / password: {{ vm_passwords['worker1'] }}"
        echo "worker2 -> user: {{ vm_ssh_user }} / password: {{ vm_passwords['worker2'] }}"
      args:
        executable: /bin/bash
      changed_when: false
